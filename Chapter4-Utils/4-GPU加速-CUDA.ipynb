{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-GPU加速-CUDA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grK_a_hGFTU1",
        "colab_type": "text"
      },
      "source": [
        "## GPU加速\n",
        "\n",
        "在PyTorch中以下数据结构分为CPU和GPU两个版本：\n",
        "- Tensor\n",
        "- nn.Module（包括常用的layer、loss function，以及容器Sequential等）\n",
        "\n",
        "它们都带有一个`.cuda`方法，调用此方法即可将其转为对应的GPU对象。  \n",
        "注意： \n",
        "- `tensor.cuda`会返回一个新对象，这个新对象的数据已转移至GPU，而之前的tensor还在原来的设备上（CPU）\n",
        "- 而`module.cuda`则会将所有的数据都迁移至GPU，并返回自己。所以`module = module.cuda()`和`module.cuda()`所起的作用一致。 \n",
        "\n",
        "nn.Module在GPU与CPU之间的转换，本质上还是利用了Tensor在GPU和CPU之间的转换。   \n",
        "`nn.Module`的cuda方法是将nn.Module下的所有parameter（包括子module的parameter）都转移至GPU，而Parameter本质上也是tensor(Tensor的子类)。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xovZNBRzFd0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ZrXTByFTU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27150799-30db-4faf-923a-e0afacfca159"
      },
      "source": [
        "# 因需要GPU，要在colab完成  \n",
        "tensor = t.Tensor(3, 4)\n",
        "\n",
        "# 返回一个新的tensor，保存在第1块GPU上，但原来的tensor并没有改变\n",
        "tensor.cuda(0)\n",
        "\n",
        "tensor.is_cuda"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4RmjDdMFpd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33203d42-f7f6-4947-db06-c2eaf29ba9f2"
      },
      "source": [
        "# 不指定所使用的GPU设备，将默认使用第1块GPU\n",
        "tensor = tensor.cuda()\n",
        "tensor.is_cuda"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbtkSmo-GJGP",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 GPU使用建议     \n",
        "- GPU运算很快，但对于很小的运算量来说，并不能体现出它的优势，因此对于一些简单的操作可直接利用CPU完成\n",
        "- 数据在CPU和GPU之间，以及GPU与GPU之间的传递会比较耗时，应当尽量避免\n",
        "- 在进行低精度的计算时，可以考虑`HalfTensor`，它相比于`FloatTensor`能节省一半的显存，但需千万注意数值溢出的情况"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDrFhsS1GYcg",
        "colab_type": "text"
      },
      "source": [
        "专门提一下，大部分的损失函数也都属于`nn.Moudle`，但在使用GPU时，很多时候我们都忘记使用它的`.cuda`方法，这在大多数情况下不会报错，因为损失函数本身没有可学习的参数（learnable parameters）。但在某些情况下会出现问题，为了保险起见同时也为了代码更规范，应记得调用`criterion.cuda`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBsiKueHGiKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58252877-6d7a-4e3a-d318-b65e96d55b97"
      },
      "source": [
        "criterion = t.nn.CrossEntropyLoss(weight=t.Tensor([1, 3]))\n",
        "\n",
        "input = t.randn(4, 2).cuda()\n",
        "target = t.Tensor([1, 0, 0, 1]).long().cuda()\n",
        "\n",
        "criterion.cuda()\n",
        "loss = criterion(input, target)\n",
        "criterion._buffers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([1., 3.], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw45aqtnIl8J",
        "colab_type": "text"
      },
      "source": [
        "而除了调用对象的`.cuda`方法之外，还可以使用`torch.cuda.device`，来指定默认使用哪一块GPU，或使用`torch.set_default_tensor_type`使程序默认使用GPU，不需要手动调用cuda。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqmph52EI0sM",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 GPU切换     \n",
        "如果服务器具有多个GPU，`tensor.cuda()`方法会将tensor保存到第一块GPU上，等价于`tensor.cuda(0)`。此时如果想使用第二块GPU，需手动指定`tensor.cuda(1)`，而这需要修改大量代码，很是繁琐。这里有两种替代方法：\n",
        "\n",
        "- 一种是先调用`t.cuda.set_device(1)`指定使用第二块GPU，后续的`.cuda()`都无需更改，切换GPU只需修改这一行代码。\n",
        "- 更推荐的方法是设置环境变量`CUDA_VISIBLE_DEVICES`，例如当`export CUDA_VISIBLE_DEVICE=1`（下标是从0开始，1代表第二块GPU），只使用第二块物理GPU，但在程序中这块GPU会被看成是第一块逻辑GPU，因此此时调用`tensor.cuda()`会将Tensor转移至第二块物理GPU。`CUDA_VISIBLE_DEVICES`还可以指定多个GPU，如`export CUDA_VISIBLE_DEVICES=0,2,3`，那么第一、三、四块物理GPU会被映射成第一、二、三块逻辑GPU，`tensor.cuda(1)`会将Tensor转移到第三块物理GPU上。\n",
        "\n",
        "设置`CUDA_VISIBLE_DEVICES`有两种方法，一种是在命令行中`CUDA_VISIBLE_DEVICES=0,1 python main.py`，一种是在程序中`import os;os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"`。如果使用IPython或者Jupyter notebook，还可以使用`%env CUDA_VISIBLE_DEVICES=1,2`来设置环境变量。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgqfE4Y6JGiy",
        "colab_type": "text"
      },
      "source": [
        "从 0.4 版本开始，pytorch新增了`tensor.to(device)`方法，能够实现设备透明，便于实现CPU/GPU兼容"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-IK9-a1JJx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}